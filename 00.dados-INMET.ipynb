{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from hidromet.INMET import INMET\n",
    "from hidromet import config\n",
    "from hidromet import contornos\n",
    "from hidromet import limpeza\n",
    "from hidromet import modelos\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obter inventário de postos do INMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmet = INMET()\n",
    "estacoes = inmet.listar_estacoes()\n",
    "df_estacoes = pd.DataFrame(estacoes)\n",
    "\n",
    "df_estacoes.loc[:, [\"VL_LATITUDE\", \"VL_LONGITUDE\"]] = df_estacoes.loc[:, [\"VL_LATITUDE\", \"VL_LONGITUDE\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recortar postos dentro do contorno das bacias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9d9a5",
   "metadata": {},
   "source": [
    "## Postos do INMET dentro dos contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(config.dir_contorno)\n",
    "\n",
    "coordenadas = contornos.zipar_coordenadas(latitude=df_estacoes.VL_LATITUDE, longitude=df_estacoes.VL_LONGITUDE)\n",
    "postos_plu = contornos.criar_geodataframe(coordenadas=coordenadas, df=df_estacoes)\n",
    "postos_plu.set_index(\"CD_ESTACAO\", inplace=True)\n",
    "\n",
    "geometria = gdf.iloc[0].geometry\n",
    "bacia = gdf.iloc[0].bacia\n",
    "postos = postos_plu.geometry\n",
    "\n",
    "postos_inmet_dentro = contornos.recortar_postos(postos=postos, contorno=geometria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter séries de chuva por bacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_bacia = config.dir_prec_inmet.joinpath(f\"{bacia}.csv\")\n",
    "data_inicial = \"2000-01-01\" \n",
    "hoje = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bacia_df = limpeza.remover_codigos_duplicados(postos_inmet_dentro)\n",
    "n_postos = len(bacia_df.index)\n",
    "\n",
    "chuvas_bacia = list()\n",
    "postos_sem_dado = list()\n",
    "postos_com_falha = list()\n",
    "postos_nao_representativos = list()\n",
    "postos_ok = list()\n",
    "for estacao in bacia_df.index:\n",
    "    coordenadas = bacia_df.loc[estacao, 'geometry']\n",
    "    estacao_json = inmet.obter_dados_estacao(cod_estacao=estacao, data_inicial=data_inicial, data_final=hoje, freq=\"D\")\n",
    "    df = pd.DataFrame(estacao_json)\n",
    "    df.rename({\"DT_MEDICAO\": \"data\", \"CHUVA\": estacao}, axis=1, inplace=True)\n",
    "    df.set_index(\"data\", inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df = df[[estacao]].apply(pd.to_numeric)\n",
    "\n",
    "    df = limpeza.remover_duplicados(df)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df[estacao] = limpeza.remover_outliers(df[estacao], p=0.99)\n",
    "    df[estacao] = limpeza.substituir_negativos(df[estacao])\n",
    "    falhas = limpeza.contabilizar_falhas(df[estacao])\n",
    "    df = limpeza.remover_meses_nao_representativos(df)\n",
    "    anos_disponiveis = limpeza.anos_disponiveis(df)\n",
    "    n_dados = len(df)\n",
    "\n",
    "    info_posto = modelos.Posto(\n",
    "        latitude=coordenadas.y,\n",
    "        longitude=coordenadas.x,\n",
    "        codigo=estacao,\n",
    "        n_dados=n_dados\n",
    "    )\n",
    "\n",
    "\n",
    "    if not df.empty and falhas < 0.15 and anos_disponiveis > 8:\n",
    "        postos_ok.append(info_posto)\n",
    "        chuvas_bacia.append(df)\n",
    "    elif df.empty:\n",
    "        postos_sem_dado.append(info_posto)\n",
    "    elif anos_disponiveis < 8: \n",
    "        postos_nao_representativos.append(info_posto)\n",
    "    elif falhas > 0.15:\n",
    "        postos_com_falha.append(info_posto)\n",
    "\n",
    "\n",
    "info_bacia = modelos.Bacia(\n",
    "    serie_vazia=postos_sem_dado,\n",
    "    nao_representativos=postos_nao_representativos,\n",
    "    com_falhas=postos_com_falha,\n",
    "    postos_ok=postos_ok,\n",
    "    n_postos=n_postos,\n",
    "    bacia=bacia\n",
    ")\n",
    "\n",
    "\n",
    "df_chuva = pd.concat(chuvas_bacia, axis=1)\n",
    "df_chuva.to_csv(arquivo_bacia)\n",
    "\n",
    "arquivo_json = Path(config.dir_prec_inmet, f'coords_{bacia}.json')\n",
    "with open(arquivo_json, 'w') as f:\n",
    "    json.dump(info_bacia.dict(), f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9405e057c29e55d40f52fc1b8f962b8e766a6021da215d95862c1278d4851e42"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('datathons-2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
